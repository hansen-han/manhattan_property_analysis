{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Manhattan Real Estate Data\n",
    "This is a workflow for using the ```zillow_scraper``` package (https://github.com/hansenrhan/zillow_scraper) to collect rental and sales data in Manhattan in 2024. The ultimate goal is to do comparisons between rental vs. buying apartments in Manhattan, and evaluate how buying property in Manhattan compares to other possible investments such index funds.\n",
    "\n",
    "Author: Hansen Han    \n",
    "Date: April 7, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages, Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "from zillow_scraper import zillow_scraper, make_frame_sales, make_frame_rentals, make_frame_rentals_detail\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set config\n",
    "warnings.flterwarnings('ignore')\n",
    "today = datetime.now()\n",
    "todays_date = today.strftime(\"%Y_%m_%d\")\n",
    "todays_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def extract_zillow_page_json_modified(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Locate the <script> tag with the specified id\n",
    "    script_tag = soup.find('script', {'id': '__NEXT_DATA__'})\n",
    "\n",
    "    data = None\n",
    "    # Extract the JSON content (if the tag is found)\n",
    "    if script_tag:\n",
    "        json_content = script_tag.string\n",
    "        # Now, you can parse the json_content using json.loads\n",
    "        data = json.loads(json_content)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def average_time_between_dates(date_strings):\n",
    "    # Convert string dates to datetime objects\n",
    "    dates = [datetime.strptime(date_str, '%Y-%m-%d') for date_str in date_strings]\n",
    "\n",
    "    # Calculate time differences between consecutive dates\n",
    "    time_diffs = [dates[i+1] - dates[i] for i in range(len(dates)-1)]\n",
    "\n",
    "    # Calculate total time difference and number of differences\n",
    "    total_time_diff = sum(time_diffs, datetime.min - datetime.min)\n",
    "    num_diffs = len(time_diffs)\n",
    "\n",
    "    # Calculate average time difference\n",
    "    average_time_diff = total_time_diff / num_diffs\n",
    "\n",
    "    return average_time_diff\n",
    "\n",
    "def total_years_between_dates(date_strings):\n",
    "    # Convert string dates to datetime objects\n",
    "    dates = [datetime.strptime(date_str, '%Y-%m-%d') for date_str in date_strings]\n",
    "\n",
    "    # Find the minimum and maximum dates\n",
    "    min_date = min(dates)\n",
    "    max_date = max(dates)\n",
    "\n",
    "    # Calculate the difference in years between the minimum and maximum dates\n",
    "    total_years = (max_date - min_date).days / 365.25\n",
    "\n",
    "    return total_years\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_cagr(initial_value, final_value, periods):\n",
    "    \"\"\"\n",
    "    Calculate Compound Annual Growth Rate (CAGR)\n",
    "    \n",
    "    Parameters:\n",
    "        initial_value (float): Initial value\n",
    "        final_value (float): Final value\n",
    "        periods (int): Number of periods\n",
    "        \n",
    "    Returns:\n",
    "        float: Compound Annual Growth Rate (CAGR)\n",
    "    \"\"\"\n",
    "    cagr = (final_value / initial_value) ** (1 / periods) - 1\n",
    "    return cagr\n",
    "\n",
    "\n",
    "def sales_stats_calculator(price_data):\n",
    "    # calculate price history data of interest\n",
    "    # total sales events\n",
    "    # average time between sales\n",
    "    # appreciation \n",
    "    # total return\n",
    "    # time range\n",
    "    # stdev_price\n",
    "    sales_events = None\n",
    "    try:\n",
    "        \n",
    "        # we only want to see sales\n",
    "        price_data = price_data[price_data.event == \"Sold\"]\n",
    "        price_data = price_data.reset_index(drop=True)\n",
    "\n",
    "        sales_events = len(price_data['event'])\n",
    "        \n",
    "        # if we have less than 2 events, we can't calculate stats\n",
    "        if sales_events < 2:\n",
    "            return sales_events, None, None, None, None, None\n",
    "\n",
    "        # calculate the average time between sales\n",
    "        dates = price_data['date']\n",
    "        average_time_between_sales = average_time_between_dates(dates)\n",
    "\n",
    "        # calculate cumulative appreciation \n",
    "        time_range = total_years_between_dates(dates)\n",
    "\n",
    "        # calculate maximum drawdown (lowest point relative to initial)\n",
    "        earliest_sale_price = price_data['price'][len(price_data) - 1]\n",
    "        lowest_price = earliest_sale_price\n",
    "        for sale_price in list(price_data['price']):\n",
    "            if sale_price < lowest_price:\n",
    "                lowest_price = sale_price\n",
    "        \n",
    "        max_drawdown = round(lowest_price/earliest_sale_price, 2) - 1\n",
    "\n",
    "        # calculate total return\n",
    "        latest_sale_price = price_data['price'][0]\n",
    "        total_return = latest_sale_price/earliest_sale_price - 1\n",
    "        annual_return_raw = total_return/time_range\n",
    "\n",
    "        # calculate compound annual growth rate(CAGR)\n",
    "        cagr = calculate_cagr(earliest_sale_price, latest_sale_price, time_range)\n",
    "\n",
    "        return sales_events, average_time_between_sales.days / 365.25, time_range, max_drawdown, total_return, cagr\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        traceback.print_exc()\n",
    "        return sales_events, None, None, None, None, None\n",
    "\n",
    "\n",
    "def get_hoa_fee_from_html(html):\n",
    "    try:\n",
    "        # Initialize a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the span containing \"monthly HOA fee\"\n",
    "        target_span = soup.find('span', string=re.compile(r'HOA fee'))\n",
    "\n",
    "        if target_span:\n",
    "            \n",
    "            text_content = target_span.string\n",
    "            if text_content:\n",
    "                text_content = text_content.replace(\"$\", \"\").replace(\",\", \"\").replace(\"HOA fee:\", \"\").replace(\"monthly\", \"\").replace(\" \", \"\")\n",
    "                number = float(text_content)\n",
    "            # Extract the number from the string\n",
    "            #number_match = re.search(r'\\$(\\d+)', text_content)\n",
    "            \n",
    "            if number:\n",
    "                #number = int(number_match.group(1))\n",
    "                return number\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_capitalization_variations(string, index, current_variation, all_variations):\n",
    "    if index == len(string):\n",
    "        all_variations.append(current_variation)\n",
    "        return\n",
    "    \n",
    "    char = string[index]\n",
    "    \n",
    "    # Lowercase variation\n",
    "    generate_capitalization_variations(string, index + 1, current_variation + char.lower(), all_variations)\n",
    "    \n",
    "    # Uppercase variation\n",
    "    generate_capitalization_variations(string, index + 1, current_variation + char.upper(), all_variations)\n",
    "\n",
    "\n",
    "def extract_building_type(building_num, street):\n",
    "    search_query = \"1|{building_num}|{street}|1\".format(building_num = building_num, street=street)\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        }\n",
    "\n",
    "\n",
    "        url = \"https://a810-dobnow.nyc.gov/Publish/WrapperPP/PublicPortal.svc/getPublicPortalPropertyDetailsGet/{search_query}\".format(search_query=quote(search_query))\n",
    "        r = requests.get(url, headers=headers)\n",
    "        prop_dict = json.loads(r.text)\n",
    "        return prop_dict['PropertyDetails']['VlFinaOccpncy']\n",
    "    except Exception as e:\n",
    "        print(\"Error in extract_builing_type():\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Current Rental & Sales Listings for Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "property_types = [\"sale\", \"rent\"]\n",
    "location = \"manhattan-ny\"\n",
    "\n",
    "for property_type in property_types:\n",
    "    data_dict = zillow_scraper(city=location, property_type=property_type, time_between_scrapes=120, testing=False, min_price=0)\n",
    "\n",
    "    data = data_dict[\"data_list\"]\n",
    "    min_price = data_dict[\"min_price\"]\n",
    "    num_listings = data_dict[\"num_listings\"]\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # sales properties need to be handled slightly different...\n",
    "    if property_type == \"sale\":\n",
    "        # extract into a table\n",
    "        df = make_frame_sales(df, data)\n",
    "\n",
    "        #drop cols\n",
    "        #df = df.drop('hdpData', 1) #remove this line to see a whole bunch of other random cols, in dict format\n",
    "\n",
    "        #drop dupes\n",
    "        df = df.drop_duplicates(subset='zpid', keep=\"last\")\n",
    "\n",
    "        #filters\n",
    "        df['zestimate'] = df['zestimate'].fillna(0)\n",
    "        df['best_deal'] = df['unformattedPrice'] - df['zestimate']\n",
    "    else:\n",
    "        df = make_frame_rentals_detail(df, data)\n",
    "    \n",
    "    df.to_csv(\"data/{location}_{property_type}_{date}.csv\".format(location=location, property_type=property_type, date=todays_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Historical Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Additional Sale Listing Information (HOA Fee, Historical Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Sales Data\n",
    "sales_data = pd.read_csv(\"manhattan-ny_sale_2024_03_15.csv\")\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from zillow_scraper import get_hoa_fee\n",
    "\n",
    "sales_events_results = []\n",
    "avg_years_between_sales_results = []\n",
    "total_range_results = []\n",
    "max_drawdown_results = []\n",
    "total_return_results = []\n",
    "cagr_results = []\n",
    "hoa_fees = []\n",
    "rent_zestimates = []\n",
    "\n",
    "for url in tqdm(sales_data['detailUrl']):\n",
    "    html_content = None\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        # open the page\n",
    "        driver.get(url)\n",
    "\n",
    "        html_content = driver.page_source\n",
    "        driver.quit()\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        pass\n",
    "\n",
    "    data = extract_zillow_page_json_modified(html_content)\n",
    "\n",
    "    sub_data = json.loads(data['props']['pageProps']['componentProps']['gdpClientCache'])\n",
    "\n",
    "    # extract and calculate information about property sales\n",
    "    price_history_df = pd.DataFrame(sub_data[list(sub_data.keys())[0]]['property']['priceHistory'])\n",
    "    sales_events, avg_years_between_sales, total_range, max_drawdown, total_return, cagr = sales_stats_calculator(price_history_df)\n",
    "    sales_events_results.append(sales_events)\n",
    "    avg_years_between_sales_results.append(avg_years_between_sales)\n",
    "    total_range_results.append(total_range)\n",
    "    max_drawdown_results.append(max_drawdown)\n",
    "    total_return_results.append(total_return)\n",
    "    cagr_results.append(cagr)\n",
    "\n",
    "    # record HOA fees\n",
    "    try:\n",
    "        hoa_fee = float(sub_data[list(sub_data.keys())[0]]['property']['resoFacts']['hoaFeeTotal'].replace(\"$\", \"\").replace(\",\", \"\").replace(\" monthly\", \"\"))\n",
    "    except:\n",
    "        hoa_fee = None\n",
    "    hoa_fees.append(hoa_fee)\n",
    "\n",
    "    # record rental estimate from zillow\n",
    "    try:\n",
    "        rent_zestimate = float(sub_data[list(sub_data.keys())[0]]['property']['rentZestimate'])\n",
    "    except:\n",
    "        rent_zestimate = None\n",
    "    rent_zestimates.append(rent_zestimate)\n",
    "\n",
    "\n",
    "    #time.sleep(45) # sleep for 45 seconds\n",
    "\n",
    "sales_data['sales_events'] = sales_events_results\n",
    "sales_data['avg_years_between_sales'] = avg_years_between_sales_results\n",
    "sales_data['total_range_sales'] = total_range_results\n",
    "sales_data['max_sales_loss'] = max_drawdown_results\n",
    "sales_data['total_return'] = total_return_results\n",
    "sales_data['historical_cagr'] = cagr_results\n",
    "sales_data['hoa_fee'] = hoa_fees\n",
    "sales_data['rent_zestimate'] = rent_zestimates\n",
    "\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Building Type (Condo or Co-Op?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generate an array of combinations of potential prefixes to an address to handle\n",
    "# We just want the building address, so we need to remove any possible extra information\n",
    "# ...otherwise we won't be able to programatically search from the Department of Buildings...\n",
    "\n",
    "split_chs = [\"#\", \"Unit\", \"Apt\", \"Penthouse\", \"Floor\", \"Room\", \"Ph\", \"Suite\", \"Front\"]\n",
    "all_variations = []\n",
    "\n",
    "for ch in split_chs:\n",
    "    generate_capitalization_variations(ch, 0, \"\", all_variations)\n",
    "\n",
    "\n",
    "split_chs = [\" \" + x for x in all_variations]\n",
    "split_chs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# only get building types on buildings with sales data (save time and requests)\n",
    "# if we have at least 2 points, we have points which we can calculate return over time\n",
    "filtered_sales_data = sales_data[sales_data.sales_events >= 2] #\n",
    "filtered_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# search up apartment type from the DOB\n",
    "\n",
    "building_types = []\n",
    "\n",
    "addresses = filtered_sales_data['addressStreet']\n",
    "for address in tqdm(addresses):\n",
    "    building_num = address.split(\" \")[0]\n",
    "    address = address.replace(building_num + \" \", \"\")\n",
    "    for x in split_chs:\n",
    "        if x in address:\n",
    "            address = address.split(x)[0]\n",
    "            break\n",
    "    \n",
    "    building_types.append(extract_building_type(building_num, address))\n",
    "\n",
    "building_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "filtered_sales_data.to_csv(\"data/manhattan-ny_sale_2024_03_15_with_cagr_and_hoa_fees.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
